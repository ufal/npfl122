### Lecture: 3. Temporal Difference Methods, Off-Policy Methods
#### Date: Oct 17
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl122/2223/slides/?03
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl122/2223/slides.pdf/npfl122-03.pdf, PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl122/2223/npfl122-03.mp4, Lecture
#### Questions: #lecture_3_questions
#### Lecture assignment: importance_sampling
#### Lecture assignment: q_learning
#### Lecture assignment: lunar_lander
#### Lecture assignment: td_algorithms

- Model-free and model-based methods, using state-value or action-value
  functions [Chapter 8 before Section 8.1, and Section 6.8 of RLB]
- Temporal-difference methods [Sections 6-6.3 of RLB]
- Sarsa [Section 6.4 of RLB]
- Q-learning [Section 6.5 of RLB]
- Off-policy Monte Carlo Methods [Sections 5.5-5.7 of RLB]
- Expected Sarsa [Section 6.6 of RLB]
- N-step TD policy evaluation [Section 7.1 of RLB]
- N-step Sarsa [Section 7.2 of RLB]
- Off-policy n-step Sarsa [Section 7.3 of RLB]
- Tree backup algorithm [Section 7.5 of RLB]

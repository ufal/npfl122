### Lecture: 9. Eligibility traces, Impala, R2D2, Agent57
#### Date: Nov 29
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl122/2122/slides/?09
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl122/2122/slides.pdf/npfl122-09.pdf,PDF Slides
#### Video: https://lectures.ms.mff.cuni.cz/video/rec/npfl122/2122/npfl122-2122-09.mp4, Lecture
#### Questions: #lecture_9_questions
#### Lecture assignment: brax_cheetah
#### Lecture assignment: trace_algorithms

- Eligibility traces [Sections 12, 12.1, 12.3, 12.8, 12.9 of RLB]
- TD(λ) [Section 12.2 of RLB]
- The V-trace algorithm, IMPALA [[Lasse Espeholt et al.: IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/abs/1802.01561)]
  - PBT [[Max Jaderberg et al.: Population Based Training of Neural Networks](https://arxiv.org/abs/1711.09846)]
  - PopArt reward normalization [[Matteo Hessel et al.: Multi-task Deep Reinforcement Learning with PopArt](https://arxiv.org/abs/1809.04474)]
- Transformed rewards [[Tobias Pohlen et al.: Observe and Look Further: Achieving Consistent Performance on Atari](https://arxiv.org/abs/1805.11593)]
- Recurrent Replay Distributed DQN (R2D2) [[Steven Kapturowski et al.: Recurrent Experience Replay in Distributed Reinforcement Learning](https://openreview.net/forum?id=r1lyTjAqYX)]
- Retrace [[Rémi Munos et al.:Safe and Efficient Off-Policy Reinforcement Learning](https://arxiv.org/abs/1606.02647)]
- _Never Give Up [[Adrià Puigdomènech Badia et al.: Never Give Up: Learning Directed Exploration Strategies](https://arxiv.org/abs/2002.06038)]]_
- _Agent57 [[Adrià Puigdomènech Badia et al.: Agent57: Outperforming the Atari Human Benchmark](https://arxiv.org/abs/2003.13350)]]_

### Lecture: 10. V-trace, PopArt Normalization, Partially Observable MDPs
#### Date: Dec 16
#### Slides: https://ufal.mff.cuni.cz/~straka/courses/npfl122/1920/slides/?10
#### Reading: https://ufal.mff.cuni.cz/~straka/courses/npfl122/1920/slides.pdf/npfl122-10.pdf,PDF Slides
#### Video: https://is.mff.cuni.cz/prednasky/prednaska/NPFL122/9

- The V-trace algorithm of IMPALA [[Lasse Espeholt et al.: IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures](https://arxiv.org/abs/1802.01561)]
- PopArt reward normalization [[Matteo Hessel et al.: Multi-task Deep Reinforcement Learning with PopArt](https://arxiv.org/abs/1809.04474)]
- Recurrent Replay Distributed DQN (R2D2) [[Steven Kapturowski et al.: Recurrent Experience Replay in Distributed Reinforcement Learning](https://openreview.net/forum?id=r1lyTjAqYX)]
- *MERLIN model [[Greg Wayne et al.:Unsupervised Predictive Memory in a Goal-Directed Agent](https://arxiv.org/abs/1803.10760)]*
- *FTW agent for multiplayer CTF [[Max Jaderberg et al.: Human-level performance in first-person multiplayer games with population-based deep reinforcement learning](https://arxiv.org/abs/1807.01281)]*
